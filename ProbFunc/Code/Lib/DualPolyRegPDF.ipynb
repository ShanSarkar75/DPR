{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e386623c",
   "metadata": {},
   "source": [
    "# Set of Custom Functions for Generating DualPolyRegPDF()\n",
    "\n",
    "**DualPolyRegPDF**: Dual Polynomial Regression Probabilty Desity Function\n",
    "\n",
    "### Using only TensorFlow and Keras operations\n",
    "\n",
    "**Author:** S. Sarkar\n",
    "\n",
    "**Version:** 0.00\n",
    "\n",
    "**Release:** Aug/2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c70202",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\textbf{RetFunc}\\ (\\\\\n",
    "                &x,                   &&\\text{# Input tensor (W),(B, W) or (B, C, W)}\\\\\n",
    "                &\\text{Order},        &&\\text{# Polynomial order (integer)}\\\\\n",
    "                &\\text{xMid},         &&\\text{# Boundary point separating left and right intervals}\\\\\n",
    "                &\\text{CoefLeft},     &&\\text{# Polynomial coefficients for left interval - compatible with Order}\\\\\n",
    "                &\\text{CoefRight},    &&\\text{# Polynomial coefficients for Right interval - compatible with Order}\\\\\n",
    "                &\\text{xMin},         &&\\text{# Minimum bound value for input x}\\\\\n",
    "                &\\text{xMax},         &&\\text{# Maximum bound value for input x}\\\\\n",
    "                &\\text{MinProb}=1e{-}12, &&\\text{# Minimum Clipping bound value for output probabilities}\\\\\n",
    "                &\\text{MaxProb}=1,    &&\\text{# Maximum Clipping bound value for output probabilities}\\\\\n",
    "                &\\text{Auc}=1         &&\\text{# Normalization constant (Integration PDF - Population)}\\\\\n",
    "               )\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This function maps input tensor `x` to a probability tensor using dual piecewise polynomial functions defined over [xMin, xMid] and [xMid, xMax], with coefficients `CoefLeft` and `CoefRight`, respectively.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf0832",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\textbf{Get_xTreshold}\\ (\\\\\n",
    "                            &x,                     &&\\text{# 1D input array of x-values}\\\\\n",
    "                            &y,                     &&\\text{# 1D input array of y-values}\\\\\n",
    "                            &xEdge                  &&\\text{# x Coordinate @ Edge}\\\\\n",
    "                            &\\text{ThFactor}=0.005, &&\\text{# Scaling factor for gradient threshold}\\\\\n",
    "                            &\\text{Up=False}        &&\\text{# If True: Upward Slope | Else: Downward Slope}\\\\\n",
    "                        ):\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Detects the x-value where the slope of y vs. x changes rapidly, checking the first half for upward changes \n",
    "and the second half for downward changes based on a gradient threshold scaled by ThFactor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925eafa2",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\textbf{DualPolyRegPDF}\\ (\\\\\n",
    "                  &\\text{Superset},       &&\\text{# Input tensor (Dataset)}\\\\\n",
    "                  &\\text{Points},         &&\\text{# Number of evaluation points for KDE/HDE}\\\\\n",
    "                  &\\text{PolyOrder},      &&\\text{# Polynomial order for curve fitting}\\\\ \n",
    "                  &\\text{xMin=None},      &&\\text{# Valid Lower bound - Optional}\\\\  \n",
    "                  &\\text{xMax=None},      &&\\text{# Valid Upper bound - Optional}\\\\  \n",
    "                  &\\text{TimesStd=5},     &&\\text{# Range in units of std. deviation for trimming}\\\\  \n",
    "                  &\\text{ThFactor=0.005}, &&\\text{# Scaling factor for gradient threshold detection}\\\\\n",
    "                  &\\text{UseKDE=True},    &&\\text{# If True, use KDE else HDE}\\\\\n",
    "                  &\\text{fSizeMin=3},     &&\\text{# Min. Filter Size for HDE (Gaussian Filter)}\\\\\n",
    "                  &\\text{fSigma=2.5},     &&\\text{# Smoothing Para. (h) for HDE (Gaussian Filter)}\\\\\n",
    "                  &\\text{RetProb=False},  &&\\text{# If True, return PDF else callable Func to compute Prob.}\\\\\n",
    "                  &\\text{USE_MAX_Y=True}, &&\\text{# If True, split curve at global max else at midpoint}\\\\\n",
    "                  &\\text{Print=False}     &&\\text{# If True, print debug info.}\\\\\n",
    "                         )\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This function creates a probability density function (PDF) approximation from a given dataset using either Kernel Density Estimation (KDE) or Histogram Density Estimation (HDE) on a trimmed subset of the data $\\left(\\text{within} \\le \\pm Th \\cdot \\sigma \\right)$. The resulting PDF is approximated via separate polynomial fits (least squares) on the left and right of the main peak.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5c94d",
   "metadata": {},
   "source": [
    "# Import Required Libraries \n",
    "\n",
    "**Keras Tenforflow**\n",
    "\n",
    "**NumPy**: Python package for N-dimensional arrays (Used For SciPiKDE)\n",
    "\n",
    "### For Debugging\n",
    "\n",
    "**Matplotlib**: Python plotting library\n",
    "\n",
    "**SciPy**: Gaussian KDE Using SciPy API (For validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fb9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False # Default Set it False\n",
    "# -----------------------------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from DensityEstimate import SciPyKDE, KDE, HDE\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "if DEBUG:  \n",
    "    import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1b14e",
   "metadata": {},
   "source": [
    "## RetFunc: Dual Polynomial Regression for Probability Estimation (TensorFlow)\n",
    "\n",
    "This function maps input tensor `x` to a probability tensor using dual piecewise polynomial functions defined over [xMin, xMid] and [xMid, xMax], with coefficients `CoefLeft` and `CoefRight`, respectively.\n",
    "\n",
    "### **Memory Breakdown** for `RetFunc` Function\n",
    "\n",
    "Approximate memory estimate for 1D input of length \\( W \\) and polynomial order \\( O \\) (ignoring batch size), assuming float32 data type (4 bytes):\n",
    "\n",
    "| Tensor        | Shape   | Number of elements | Memory (bytes)  | Description       |\n",
    "| ------------- | --------| ------------------ | --------------- | ----------------- |\n",
    "| **x**         | (W,)    | W                  | 4 \\* W          | Input vector      |\n",
    "| **powers**    | (O,)    | O                  | 4 \\* O          | Powers vector     |\n",
    "| **xExpand**   | (W, 1)  | W                  | 4 \\* W          | Expanded input    |\n",
    "| **xPow**      | (W, O)  | W \\* O             | 4 \\* W \\* O     | Powers of input   |\n",
    "| **CoefLeft**  | (1, O)  | O                  | 4 \\* O          | Coefficients      |\n",
    "| **CoefRight** | (1, O)  | O                  | 4 \\* O          | Coefficients      |\n",
    "| **yLeftRaw**  | (W,)    | W                  | 4 \\* W          | Polynomial result |\n",
    "| **yRightRaw** | (W,)    | W                  | 4 \\* W          | Polynomial result |\n",
    "| **IdxLeft**   | (W,)    | W                  | 4 \\* W          | Mask              |\n",
    "| **IdxRight**  | (W,)    | W                  | 4 \\* W          | Mask              |\n",
    "| **Prob**      | (W,)    | W                  | 4 \\* W          | Final output      |\n",
    "\n",
    "Total memory (approximate):\n",
    "\n",
    "$$\n",
    "\\text{Memory} \\approx 4 \\times \\big( 7W + 3 \\times \\text{O} + W \\times \\text{Order} \\big) \\quad \\text{bytes}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Memory}_{\\text{KB}} = \\frac{\\text{Memory}}{1024} = \\frac{4 \\times (7W + 3O + W \\times O)}{1024} \\quad \\text{KB}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Memory}_{\\text{MB}} = \\frac{\\text{Memory}}{1024^2} = \\frac{4 \\times (7W + 3O + W \\times O)}{1024^2} \\quad \\text{MB}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be2c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RetFunc: Dual Polynomial Regression for Probability Estimation (TensorFlow)\n",
    "\n",
    "Computes piecewise polynomial regression-based probabilities over input tensor `x`, \n",
    "with separate polynomial coefficients applied on left and right intervals defined by `xMid`. \n",
    "\n",
    "Parameters:\n",
    "- x: Input tensor of shape (WinSize),(Batch, WinSize) or (Batch, WinNo, WinSize)\n",
    "- Order: Polynomial order (integer)\n",
    "- xMid: Boundary point separating left and right intervals (scalar)\n",
    "- CoefLeft: Polynomial coefficients for left interval, shape compatible with `Order`\n",
    "- CoefRight: Polynomial coefficients for right interval, shape compatible with `Order`\n",
    "- xMin, xMax: Minimum and maximum bounds for input values\n",
    "- MinProb, MaxProb: Clipping bounds for output probabilities\n",
    "- Auc: Normalization constant (area under curve)\n",
    "\n",
    "Returns:\n",
    "- Probabilities tensor of same shape as `x`.\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "@tf.function(reduce_retracing=True)\n",
    "def RetFunc(x,                  # Input tensor (W),(B, W) or (B, C, W)\n",
    "            Order,              # Polynomial order (integer)           \n",
    "            xMid,               # Boundary point separating left and right intervals \n",
    "            CoefLeft,           # Polynomial coefficients for left interval - compatible with `Order`\n",
    "            CoefRight,          # Polynomial coefficients for Right interval - compatible with `Order` \n",
    "            xMin,               # Minimum bound value for input x\n",
    "            xMax,               # Maximum bound value for input x\n",
    "            MinProb=1e-12,      # Minimum Clipping bound value for output probabilities\n",
    "            MaxProb=1,          # Maximum Clipping bound value for output probabilities\n",
    "            Auc=1):             # Normalization constant (Area Under Curve - PDF of Population)\n",
    "\n",
    "    \"\"\"\n",
    "    x: Tensor of shape (WinSize), (Batch, WinSize) or (Batch, WinNo, WinSize)\n",
    "    Returns: Probabilities of same shape\n",
    "    \"\"\"\n",
    "    x = tf.cast(x, tf.float32)                     # shape: (Batch, WinSize) or (Batch, WinNo, WinSize)\n",
    "\n",
    "    powers = tf.range(Order, dtype=tf.float32)     # shape: (Order,)\n",
    "    xExpand = tf.expand_dims(x, axis=-1)           # shape (..., 1)\n",
    "    xPow = tf.pow(xExpand, powers)                 # shape (..., Order)\n",
    "\n",
    "    # Reshape coefficients for broadcasting\n",
    "    ExpandShape = [1] * (len(x.shape)) + [Order]   # shape: [1, 1, ..., Order] matching xPow trailing dim\n",
    "    CoefLeft = tf.reshape(CoefLeft, ExpandShape)   # shape: ExpandShape (broadcastable)\n",
    "    CoefRight = tf.reshape(CoefRight, ExpandShape) # shape: ExpandShape (broadcastable)\n",
    "    \n",
    "    # Compute polynomials via einsum (more optimized on GPUs)\n",
    "    #yLeftRaw = tf.reduce_sum(xPow * CoefLeft, axis=-1)\n",
    "    yLeftRaw = tf.einsum('...o,...o->...', xPow, CoefLeft)    # shape: same as x without last dim\n",
    "    # yRight = tf.reduce_sum(xPow * CoefRight, axis=-1)\n",
    "    yRightRaw = tf.einsum('...o,...o->...', xPow, CoefRight)  # shape: same as x without last dim\n",
    "\n",
    "    # Create masks\n",
    "    # First index where x >= xMid\n",
    "    Pointer = tf.argmax(tf.cast(x >= xMid, tf.float32), axis=-1, output_type=tf.int32)  \n",
    "    # Create indices vector for last axis\n",
    "    length = tf.shape(x)[-1]  # length of last axis\n",
    "    idxs = tf.range(length)  # shape: (length,)\n",
    "    # Reshape idxs for broadcasting, e.g., for 2D x with shape (B,L), idxs shape becomes (1,L)\n",
    "    # For 3D shape (B1,B2,L), idxs shape will be (1,1,L)\n",
    "    expand_shape = tf.concat([tf.ones(tf.rank(x)-1, dtype=tf.int32), [length]], axis=0)\n",
    "    idxs_exp = tf.reshape(idxs, expand_shape)  # shape compatible for broadcasting with x and Pointer\n",
    "    # Expand Pointer dims to add last dim for broadcasting\n",
    "    Pointer_exp = tf.expand_dims(Pointer, axis=-1)  # shape: x.shape[:-1] + (1,)\n",
    "    # MaskLeft: indices less than Pointer are 1, else 0\n",
    "    MaskLeft = tf.cast(idxs_exp < Pointer_exp, tf.float32)\n",
    "    # MaskRight: indices greater or equal to Pointer are 1, else 0\n",
    "    MaskRight = tf.cast(idxs_exp >= Pointer_exp, tf.float32)\n",
    "    EdgeMask = tf.cast(tf.logical_and(x >= xMin, x < xMax), tf.float32)\n",
    "    # Apply masks and normalize\n",
    "    Prob = (yLeftRaw * MaskLeft + yRightRaw * MaskRight) / Auc  # shape: same as x without last dim\n",
    "    Prob = Prob*EdgeMask\n",
    "    Prob = tf.clip_by_value(Prob, MinProb, MaxProb)             # shape: same as x without last dim       \n",
    "    return Prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b09d62",
   "metadata": {},
   "source": [
    "## For Evaluation / Debugging Purpose - RetFunc Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de7e1e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#*************************************************************\n",
    "# Test Code\n",
    "#*************************************************************\n",
    "if DEBUG:\n",
    "    @tf.function#(reduce_retracing=True)\n",
    "    def pRetFunc(x, Order, xMid, CoefLeft, CoefRight, \n",
    "                xMin, xMax, MinProb=1e-12, MaxProb=1, Auc=1, Print=False):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (Batch, WinSize) or (Batch, WinNo, WinSize)\n",
    "        Returns: Probabilities of same shape (and memory if RetMem)\n",
    "        \"\"\"\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        if Print: tf.print('1. x: ', x.shape)\n",
    "\n",
    "        powers = tf.range(Order, dtype=tf.float32)\n",
    "        if Print: tf.print('2. powers: ', powers.shape)\n",
    "\n",
    "        xExpand = tf.expand_dims(x, axis=-1)           # shape (..., 1)\n",
    "        if Print: tf.print('3. xExpand: ', xExpand.shape)\n",
    "\n",
    "        xPow = tf.pow(xExpand, powers)                 # shape (..., Order)\n",
    "        if Print: tf.print('4. xPow: ', xPow.shape)\n",
    "\n",
    "        # Reshape coefficients for broadcasting\n",
    "        ExpandShape = [1] * (len(x.shape)) + [Order]   # shape: [1, 1, ..., Order] matching xPow trailing dim\n",
    "        if Print: tf.print('5. ExpandShape: ', ExpandShape)\n",
    "\n",
    "        CoefLeft = tf.reshape(CoefLeft, ExpandShape)   # shape: ExpandShape (broadcastable)\n",
    "        if Print: tf.print('6. CoefLeft: ', CoefLeft.shape,' CoefLeft: ',CoefLeft)\n",
    "        CoefRight = tf.reshape(CoefRight, ExpandShape) # shape: ExpandShape (broadcastable)\n",
    "        if Print: tf.print('7. CoefRight: ', CoefRight.shape, ' CoefRight: ',CoefRight)\n",
    "\n",
    "        # Compute polynomials via einsum (more optimized on GPUs)\n",
    "        #yLeftRaw = tf.reduce_sum(xPow * CoefLeft, axis=-1)\n",
    "        yLeftRaw = tf.einsum('...o,...o->...', xPow, CoefLeft)    # shape: same as x without last dim\n",
    "        if Print: tf.print('8. yLeftRaw: ', yLeftRaw.shape); \n",
    "        #tf.print('8A. yLeftRaw: ', yLeftRaw, summarize=-1)\n",
    "        #yRightRaw = tf.reduce_sum(xPow * CoefRight, axis=-1)\n",
    "        yRightRaw = tf.einsum('...o,...o->...', xPow, CoefRight)  # shape: same as x without last dim\n",
    "        if Print: tf.print('9. yRightRaw: ', yRightRaw.shape); \n",
    "        #tf.print('9A. yRightRaw: ', yRightRaw, summarize=-1)\n",
    "\n",
    "        # Create masks\n",
    "        Pointer = tf.argmax(tf.cast(x >= xMid, tf.float32), axis=-1, output_type=tf.int32)  # First index where x >= xMid\n",
    "        if Print: tf.print(\"Pointer dtype:\", Pointer.dtype)\n",
    "        # Create indices vector for last axis\n",
    "        length = tf.shape(x)[-1]  # length of last axis\n",
    "        idxs = tf.range(length)  # shape: (length,)\n",
    "        # Reshape idxs for broadcasting, e.g., for 2D x with shape (B,L), idxs shape becomes (1,L)\n",
    "        # For 3D shape (B1,B2,L), idxs shape will be (1,1,L)\n",
    "        expand_shape = tf.concat([tf.ones(tf.rank(x)-1, dtype=tf.int32), [length]], axis=0)\n",
    "        idxs_exp = tf.reshape(idxs, expand_shape)  # shape compatible for broadcasting with x and Pointer\n",
    "        # Expand Pointer dims to add last dim for broadcasting\n",
    "        Pointer_exp = tf.expand_dims(Pointer, axis=-1)  # shape: x.shape[:-1] + (1,)\n",
    "        # MaskLeft: indices less than Pointer are 1, else 0\n",
    "        MaskLeft = tf.cast(idxs_exp < Pointer_exp, tf.float32)\n",
    "        if Print:\n",
    "            Tot1 = tf.reduce_sum(MaskLeft)\n",
    "            tf.print(f'MaskLeft:', tf.shape(MaskLeft), '  Tot1:',Tot1)\n",
    "            tf.print(MaskLeft)\n",
    "        \n",
    "        # MaskRight: indices greater or equal to Pointer are 1, else 0\n",
    "        MaskRight = tf.cast(idxs_exp >= Pointer_exp, tf.float32)\n",
    "        if Print:\n",
    "            Tot1 = tf.reduce_sum(MaskRight)\n",
    "            tf.print(f'MaskRight:', tf.size(MaskRight), '  Tot1:',Tot1)\n",
    "            tf.print(MaskRight)\n",
    "        \n",
    "        EdgeMask = tf.cast(tf.logical_and(x >= xMin, x < xMax), tf.float32)\n",
    "        if Print:\n",
    "            Tot1 = tf.reduce_sum(EdgeMask)\n",
    "            tf.print(f'EdgeMask:', tf.size(EdgeMask), '  Tot1:',Tot1)\n",
    "            tf.print(EdgeMask)\n",
    "\n",
    "    \n",
    "        # Apply masks and normalize\n",
    "        Prob = (yLeftRaw * MaskLeft + yRightRaw * MaskRight) / Auc  # shape: same as x without last dim\n",
    "        Prob = Prob*EdgeMask\n",
    "        Prob = tf.clip_by_value(Prob, MinProb, MaxProb)           # shape: same as x without last dim       \n",
    "        \n",
    "        if Print: # Print the arguments Used\n",
    "            tf.print('Order', Order)\n",
    "            tf.print('xMid', xMid)\n",
    "            tf.print('xMin', xMin)\n",
    "            tf.print('xMax', xMax)\n",
    "            tf.print('MinProb', MinProb)\n",
    "            tf.print('MaxProb', MaxProb)\n",
    "            tf.print('AUC', Auc)\n",
    "        \n",
    "        return Prob   \n",
    "\n",
    "    #=====================================================================\n",
    "    Order = 2\n",
    "    xMin, xMid, xMax = -0.9, 0.0, 0.9\n",
    "    MinProb, MaxProb, Auc = 1e-12, 1.0, 1.0\n",
    "    N=40; O=5 # Offset\n",
    "    # Random coefficients of shape (Order,)\n",
    "    CoefLeft =  tf.ones([Order], dtype=tf.float32)*0.1\n",
    "    CoefRight = tf.ones([Order], dtype=tf.float32)*0.1\n",
    "    X=np.linspace(-1,1,N)\n",
    "    print(f'X:{X.shape}  CoefLeft:{CoefLeft} CoefRight:{CoefRight}')    \n",
    "    #--------------------------------------------------------------------\n",
    "    # Case 1: 1D Tensor\n",
    "    x1=X\n",
    "    print(\"\\n********************************************************\")\n",
    "    print(\"Case 1: \",x1.shape)\n",
    "    print(\"********************************************************\")\n",
    "    p1 = pRetFunc(x1, Order, xMid, CoefLeft, CoefRight, xMin, xMax, MinProb, MaxProb, Auc, Print=True)\n",
    "    print(\"Case 1 output shape:\", p1.shape)\n",
    "    print(\"Case 1 output sample[100:105]:\", p1[O:O+5].numpy())\n",
    "    print(\"Case 1 output sample[-105:-100]:\", p1[N-O-5:N-O].numpy())\n",
    "    print(\"*************************************\\n\")\n",
    "    #--------------------------------------------------------------------        \n",
    "    # Case 2: 2D Tensor\n",
    "    x2 = tf.stack([X, X + 0.1])  # shape (2, 100)\n",
    "    print(\"\\n********************************************************\")\n",
    "    print(\"Case 2: \",x2.shape)\n",
    "    print(\"********************************************************\")\n",
    "    p2 = pRetFunc(x2, Order, xMid, CoefLeft, CoefRight, xMin, xMax, MinProb, MaxProb, Auc, Print=True)\n",
    "    print(\"Case 2 output shape:\", p2.shape)\n",
    "    print(\"Case 2 output sample[0,100:105]:\", p2[0, O:O+5].numpy())\n",
    "    print(\"Case 2 output sample[0,-105:-100]:\", p2[0,N-O-5:N-O].numpy())\n",
    "    print(\"*************************************\\n\")\n",
    "    #--------------------------------------------------------------------\n",
    "    # Case 3: 3D Tensor\n",
    "    x3 = tf.stack([X, X + 0.1])          # (2, 100)\n",
    "    x3 = tf.stack([x3, x3 + 0.2, x3 + 0.3], axis=1)  # (2, 3, 100)\n",
    "    print(\"\\n********************************************************\")\n",
    "    print(\"Case 3: \",x3.shape)\n",
    "    print(\"********************************************************\")\n",
    "    p3 = pRetFunc(x3, Order, xMid, CoefLeft, CoefRight, xMin, xMax, MinProb, MaxProb, Auc, Print=True)\n",
    "    print(\"Case 3 output shape:\", p2.shape)\n",
    "    print(\"Case 3 output sample[0,0,100:105]:\", p3[0,0, O:O+5].numpy())\n",
    "    print(\"Case 3 output sample[0,0,-105:-100]:\", p3[0,0,N-O-5:N-O].numpy())\n",
    "    print(\"*************************************\\n\")\n",
    "    #--------------------------------------------------------------------        \n",
    "    plt.plot(X,p1, label=f'Case1:{x1.shape}')\n",
    "    plt.plot(X,p2[1], label=f'Case2:{x2.shape}')\n",
    "    plt.plot(X,p3[1,1,:], label=f'Case3:{x3.shape}')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db9cfa",
   "metadata": {},
   "source": [
    "## Function Get_xTreshold():\n",
    "\n",
    "This function calculates a threshold point on the x-axis where the slope of y with respect to x changes significantly. For detecting upward rapid changes (when `Up=True`), it analyzes the first half of the data, and for downward rapid changes (when `Up=False`), it analyzes the second half. It computes the gradient of y over the specified half, applies a scaled threshold factor to identify where the slope crosses this threshold, and returns the corresponding x-value indicating a significant slope change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe56942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detects the x-value where the slope of y vs. x changes rapidly, checking the first half for upward changes \n",
    "and the second half for downward changes based on a gradient threshold scaled by ThFactor.\n",
    "\n",
    "Args:\n",
    "    x (array-like or tf.Tensor): 1D input array of x-values.\n",
    "    y (array-like or tf.Tensor): 1D input array of y-values.\n",
    "    xEdge (Scalar) : x Coordinate to consider as Edge - For Up: xEdge is Start For Dn: xEdge is End\n",
    "    ThFactor (float): Scaling factor for gradient threshold detection. (Default 1%)\n",
    "    Up (bool): If True, detects rapid upward slope change; \n",
    "               if False, detects rapid downward slope change.\n",
    "\n",
    "Returns:\n",
    "    float: The x-value where the slope crosses the threshold.\n",
    "\"\"\"\n",
    "\n",
    "def Get_xTreshold(x,y, xEdge,ThFactor=0.01,  Up=False):\n",
    "    # Convert tensors to NumPy arrays (float32)\n",
    "    if tf.is_tensor(x): x = x.numpy().astype(np.float32)\n",
    "    if tf.is_tensor(y): y = y.numpy().astype(np.float32)\n",
    "   \n",
    "    #For Upward Direction Consider 1st Half For Downward Direction Consider 2nd Half \n",
    "    if Up:\n",
    "        EdgeIdx=np.where(x>xEdge)[0][0] \n",
    "        sIdx=EdgeIdx\n",
    "        eIdx=max(EdgeIdx+3, x.size//2)\n",
    "    else:\n",
    "        EdgeIdx=np.where(x<xEdge)[0][-1] \n",
    "        eIdx=EdgeIdx\n",
    "        sIdx= min(x.size//2,EdgeIdx-3) \n",
    "\n",
    "    #print(f'EdgeIdx:{EdgeIdx} sIdx:{sIdx} eIdx:{eIdx}')\n",
    "    # Compute first derivative\n",
    "    dy = np.gradient(y[sIdx:eIdx], x[sIdx:eIdx])\n",
    "    # Thresholding: \n",
    "    # For Upward Direction - Find where slope starts increasing rapidly → look where it becomes more positive\n",
    "    # For Downward Direction - Find where slope stops decreasing rapidly → look where it becomes less negative\n",
    "    threshold = ThFactor * np.max(dy)  if Up else ThFactor * np.min(dy)\n",
    "\n",
    "    idx = np.argmax(dy > threshold)\n",
    "    x_change = x[sIdx:eIdx][idx]\n",
    "    return x_change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700430b3",
   "metadata": {},
   "source": [
    "## For Evaluation / Debugging Purpose - Get_xTreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f37cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************************************************************\n",
    "# Test Code\n",
    "#*************************************************************\n",
    "if DEBUG:\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "    #-----------------------------------\n",
    "    # Case 1 - Upward Direction\n",
    "    x = np.linspace(0, 5, 500)\n",
    "    y = 1 / (1 + np.exp(-5*(x - 3)))  # sigmoid-like function with sharp rise near x=3\n",
    "    x_Up= Get_xTreshold(x,y, xEdge=2, ThFactor=0.01, Up=True)\n",
    "    ax[0].plot(x, y, label='y(x)')\n",
    "    ax[0].axvline(x_Up, color='r', linestyle='--', label=f\"Sharp Change @ x={x_Up:.2f}\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_ylabel(\"y\")\n",
    "    #-----------------------------------\n",
    "    # Case 2 - Downward -  decreasing then flattening\n",
    "    x = tf.linspace(0.0, 5.0, 500)\n",
    "    y = 1 - tf.math.sigmoid(tf.exp(x))\n",
    "    x_Dn= Get_xTreshold(x,y, xEdge=4.5, ThFactor=0.005, Up=False)\n",
    "    ax[1].plot(x, y, label='y(x)')\n",
    "    ax[1].axvline(x_Dn, color='r', linestyle='--', label=f\"Sharp Change @ x={x_Dn:.2f}\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_ylabel(\"y\")\n",
    "    #-----------------------------------\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b732e49c",
   "metadata": {},
   "source": [
    "## Creates a Dual Polynomial Function Approximating a PDF\n",
    "\n",
    "This function creates a probability density function (PDF) approximation from a given dataset using either Kernel Density Estimation (KDE) or Histogram Density Estimation (HDE) on a trimmed subset of the data $\\left(\\text{within} \\le \\pm Th \\cdot \\sigma \\right)$. The resulting PDF is approximated via separate polynomial fits (least squares) on the left and right of the main peak. \n",
    "\n",
    "During training inside `DualRegPolyPDF()`, the density function is estimated using either **KDE** (with bandwidth computed via Silverman’s rule) or **HDE** (with the number of bins determined via the Freedman–Diaconis rule).\n",
    "\n",
    "### Steps:\n",
    "    1.  Flatten and cast the input dataset to float32.\n",
    "    2.  Compute mean and standard deviation.\n",
    "    3.  Define trimming bounds (xMin, xMax) or use ±TimesStd * σ.\n",
    "    4.  Select subset within the bounds.\n",
    "    5.  Estimate density using KDE (Silverman bandwidth) or HDE.\n",
    "    6.  Sort and split density curve at maximum point.\n",
    "    7.  Identify bounds where density gradient drops below threshold.\n",
    "    8.  Fit separate polynomials to left and right intervals.\n",
    "    9.  Normalize area under the curve (AUC).\n",
    "    10. Return either normalized (x, y) points or a callable PDF function.\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9889844",
   "metadata": {},
   "source": [
    "For the fast computational method, `tf.linalg.lstsq` uses **Cholesky Decomposition** to compute the coefficients \\($ C \\in \\mathbb{R}^{N \\times K} $\\) for a given input matrix \\($ X \\in \\mathbb{R}^{M \\times N} $\\) and right-hand side \n",
    "\\($ Y \\in \\mathbb{R}^{M \\times K} $\\). The solution is computed using the **normal equations**:\n",
    "\n",
    "$$\n",
    "C = (X^\\top X)^{-1} X^\\top Y\n",
    "$$\n",
    "\n",
    "This provides the least-squares solution to the overdetermined system \\( $ XC \\approx Y $ \\), assuming \\($ X^\\top X $\\)  is full rank and well-conditioned.\n",
    "\n",
    "TensorFlow. (2024, April 26). tf.linalg.lstsq. TensorFlow API Documentation. https://www.tensorflow.org/api_docs/python/tf/linalg/lstsq  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45400170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-----------------------------------------------------------------------------\n",
    "DualPolyRegPDF: Creates a Piecewise Polynomial Function Approximating a PDF\n",
    "-----------------------------------------------------------------------------\n",
    "Args:\n",
    "    Superset (tf.Tensor): Input dataset.\n",
    "    Points (int):         Number of evaluation points for KDE/HDE.\n",
    "    PolyOrder (int):      Polynomial order for curve fitting.\n",
    "    xMin, xMax (float):   Optional explicit bounds. [Default None]\n",
    "    TimesStd (float):     Range in units of standard deviation for trimming.\n",
    "    ThFactor (float):     Scaling factor for gradient threshold detection. (Default 0.5%)\n",
    "    UseKDE (bool):        If True, use KDE; otherwise use HDE.\n",
    "    fSizeMin (int):       Minimum Filter Size - Required for HDE (Gaussian Filter). [Default 3]\n",
    "    fSigma (float):       Smoothing Parameter (h) - Required for HDE(Gaussian Filter). [Default 2.5]\n",
    "    RetProb (bool):       If True, return normalized points; else return PDF function.\n",
    "    USE_MAX_Y (bool):     If True, split curve at global max; else at midpoint.\n",
    "    Print (bool):         If True, print debug info.\n",
    "\n",
    "Returns:\n",
    "    If RetProb=True: Tuple[tf.Tensor, tf.Tensor] → (x_values, normalized_density)\n",
    "    Else: Callable[[tf.Tensor], tf.Tensor] → PDF function mapping x → probability.\n",
    "\n",
    "Possible Options:\n",
    "    - Points: Any positive integer (e.g., 100, 200, 512)\n",
    "    - PolyOrder:  Integer ≥ 1 (e.g., 3, 5, 7)\n",
    "    - xMin, xMax:  None (auto-calculated) or float values for manual bounds\n",
    "    - TimesStd:  Positive float (default=5 trims to ±TimesStd × σ)\n",
    "    - UseKDE:\n",
    "        * True → Kernel Density Estimation\n",
    "        * False → Histogram Density Estimation\n",
    "    - RetProb:\n",
    "        * True → Returns (x, normalized y)\n",
    "        * False → Returns callable PDF function\n",
    "    - Print:\n",
    "        * True → Verbose debugging output\n",
    "        * False → Silent\n",
    "    - USE_MAX_Y:\n",
    "        * True → Split at density peak\n",
    "        * False → Split at midpoint of X\n",
    "Notes:\n",
    "    - KDE bandwidth is computed using Silverman's rule.\n",
    "    - Polynomial fitting is done separately on each side of the peak to improve fit accuracy.\n",
    "    - The returned PDF function enforces clipping between MinProb and MaxProb.\n",
    "\"\"\"\n",
    "# -----------------------------------------------------------------------------\n",
    "# For Training - Should pass the whole data with outlier  \n",
    "def DualPolyRegPDF(Superset, \n",
    "                   Points=100, \n",
    "                   PolyOrder=5, \n",
    "                   xMin=None, \n",
    "                   xMax=None, \n",
    "                   TimesStd=5,\n",
    "                   ThFactor=0.01,\n",
    "                   UseKDE=True,\n",
    "                   fSizeMin=3,      # Minimum Filter Size - Required for HDE (Gaussian Filter)\n",
    "                   fSigma=2.5,      # Smoothing Parameter (h) - Required for HDE(Gaussian Filter)\n",
    "                   RetProb=False, \n",
    "                   USE_MAX_Y=True,\n",
    "                   Print=False\n",
    "                  ):\n",
    "    \n",
    "    if Print: tf.print(\"0. Superset: \",Superset.shape )\n",
    "    Superset = tf.cast(tf.reshape(Superset, [-1]), tf.float32)\n",
    "    if Print: tf.print(\"1. Superset: \",Superset.shape )\n",
    "    Epsilon = tf.constant(1e-12, tf.float32)\n",
    "    if Print: tf.print(\"2. Epsilon: \",Epsilon )\n",
    "        \n",
    "    mean, std = tf.reduce_mean(Superset), tf.math.reduce_std(Superset)\n",
    "    if Print: tf.print(\"3. mean: \",mean, \"\\tstd: \", std)\n",
    "        \n",
    "    xMinLeft = tf.cast(xMin, tf.float32) if xMin is not None else mean - TimesStd * std\n",
    "    xMaxRight = tf.cast(xMax, tf.float32) if xMax is not None else mean + TimesStd * std\n",
    "    if Print: tf.print(\"4. xMinLeft: \",xMinLeft, \"\\txMaxRight: \", xMaxRight)\n",
    "        \n",
    "    Mask99 = tf.math.logical_and(Superset > xMinLeft, Superset < xMaxRight)\n",
    "    if Print: tf.print(\"5. Mask99: \",Mask99.shape )\n",
    "        \n",
    "    # Subset using boolean_mask\n",
    "    Superset99 = tf.boolean_mask(Superset, Mask99)\n",
    "    Count99=tf.reduce_sum(tf.cast(Mask99, tf.int32))\n",
    "    if Print: \n",
    "        tf.print(\"6. Superset99: \",Superset99.shape, \"\\tCount99: \",Count99)\n",
    "        tf.print('Superset99 StdDev: ',tf.math.reduce_std(Superset99))\n",
    "    \n",
    "    # For KDE Computing BW using Silverman's rule\n",
    "    if UseKDE: X, Y = KDE(X=Superset99, Points=Points) \n",
    "    # For HDE Computing No of Bins (nBins) using Freedman–Diaconis rule\n",
    "    else: X, Y,_ = HDE(S=Superset99, nBins=None, Epsilon=Epsilon,fSizeMin=fSizeMin, fSigma=fSigma);\n",
    "    if Print: tf.print(\"7. X: \",X.shape,\"  Y: \",Y.shape)\n",
    "        \n",
    "    SortedIdx = tf.argsort(X)\n",
    "    if Print: tf.print(\"8. SortedIdx: \", SortedIdx.shape)\n",
    "    xSorted, ySorted = tf.gather(X, SortedIdx), tf.gather(Y, SortedIdx)\n",
    "    if Print: tf.print(\"9. xSorted: \",xSorted.shape, \"\\tySorted: \",ySorted.shape)\n",
    "        \n",
    "    MaxY = tf.reduce_max(ySorted)\n",
    "    MidIdx = tf.argmax(ySorted) if USE_MAX_Y else Points // 2\n",
    "    xAtMid = xSorted[MidIdx];# yAtMid=ySorted[MidIdx]\n",
    "    if Print:tf.print(\"10. MaxY:\", MaxY, \"\\tMidIdx:\", MidIdx, \"\\txAtMid:\", xAtMid)\n",
    "        \n",
    "    UpX, DnX = xSorted[:MidIdx], xSorted[MidIdx:]\n",
    "    if Print: tf.print(\"11. UpX: \",UpX.shape, \"\\tDnX: \",DnX.shape)    \n",
    "    UpY, DnY = ySorted[:MidIdx], ySorted[MidIdx:]\n",
    "    if Print: \n",
    "        tf.print(\"12. UpY: \",UpY.shape, \"\\tDnY: \",DnY.shape)\n",
    "        tf.print(\"13A. xMinLeft: \",xMinLeft )  \n",
    "        \n",
    "    # Update xMinLeft to x Point before which Gradient of y is very low\n",
    "    xUpTh=Get_xTreshold(UpX,UpY, xMinLeft, ThFactor, Up=True)\n",
    "    if xUpTh > xMinLeft: xMinLeft=xUpTh\n",
    "    if Print:         \n",
    "        tf.print(\"13. xUpTh: \",xUpTh, \"\\txMinLeft: \",xMinLeft )\n",
    "        tf.print(\"14A. xMaxRight: \",xMaxRight )  \n",
    "        \n",
    "    # Update xMaxRight to x Point after which Gradient of y is very low\n",
    "    xDnTh=Get_xTreshold(DnX,DnY, xMaxRight, ThFactor, Up=False)\n",
    "    if xDnTh < xMaxRight: xMaxRight=xDnTh\n",
    "    if Print: tf.print(\"14. xDnTh: \",xDnTh, \"\\txMaxRight: \",xMaxRight )\n",
    "        \n",
    "    xOrder = tf.stack([tf.pow(xSorted, i) for i in range(PolyOrder)], axis=1)\n",
    "    if Print: tf.print(\"15. xOrder: \", xOrder.shape)\n",
    "        \n",
    "    UpX, DnX = xOrder[:MidIdx], xOrder[MidIdx:]\n",
    "    if Print: tf.print(\"16. UpX: \",UpX.shape, \"\\tDnX: \",DnX.shape) \n",
    "    ExUpY, ExDnY = tf.expand_dims(ySorted[:MidIdx], axis=1), tf.expand_dims(ySorted[MidIdx:], axis=1)\n",
    "    if Print: tf.print(\"17. ExUpY: \",ExUpY.shape, \"\\tExDnY: \",ExDnY.shape) \n",
    "        \n",
    "    CoefUp = tf.linalg.lstsq(UpX, ExUpY)\n",
    "    CoefDn = tf.linalg.lstsq(DnX, ExDnY)\n",
    "    if Print: \n",
    "        tf.print(\"18. CoefUp: \",CoefUp.shape, \"\\tCoefDn: \",CoefDn.shape) \n",
    "        tf.print(\"18. CoefUp: \",CoefUp, \"\\tCoefDn: \",CoefDn)   \n",
    "    \n",
    "    xUp = tf.linspace(xSorted[0], xSorted[MidIdx-1], Points)\n",
    "    xDn = tf.linspace(xSorted[MidIdx], xSorted[-1], Points)\n",
    "    if Print: tf.print(\"19. xUp: \",xUp.shape, \"\\txDn: \",xDn.shape) \n",
    "        \n",
    "    yUp = tf.add_n([CoefUp[i] * tf.pow(xUp, i) for i in range(PolyOrder)])\n",
    "    yDn = tf.add_n([CoefDn[i] * tf.pow(xDn, i) for i in range(PolyOrder)])\n",
    "    if Print: tf.print(\"20. xUp: \",xUp.shape, \"\\txDn: \",xDn.shape) \n",
    "        \n",
    "    xFit = tf.concat([xDn, xUp], axis=0)\n",
    "    yFit = tf.concat([yDn, yUp], axis=0)\n",
    "    yFit = tf.clip_by_value(yFit, Epsilon, MaxY)\n",
    "    if Print: \n",
    "        tf.print(\"21. xFit: \",xFit.shape, \"\\tyFit: \",yFit.shape) \n",
    "        tf.print(\"22. Min(yFit):\", tf.reduce_min(yFit), \"\\tMax(yFit):\", tf.reduce_max(yFit))\n",
    "\n",
    "        \n",
    "    SortedIdx = tf.argsort(xFit)\n",
    "    if Print: tf.print(\"23. SortedIdx: \",SortedIdx.shape)\n",
    "        \n",
    "    xFitSorted, yFitSorted = tf.gather(xFit, SortedIdx), tf.gather(yFit, SortedIdx)\n",
    "    if Print: tf.print(\"24. xFitSorted: \",xFitSorted.shape, \"\\tyFitSorted: \",yFitSorted.shape) \n",
    "        \n",
    "    dx = xFitSorted[1:] - xFitSorted[:-1]\n",
    "    Av_dy = (yFitSorted[1:] + yFitSorted[:-1]) / 2.0\n",
    "    BaseAUC = tf.reduce_sum(dx * Av_dy)\n",
    "    if Print: tf.print(\"25. dx: \",dx.shape, \"\\tAv_dy: \",Av_dy.shape, \"\\tBaseAUC: \",BaseAUC) \n",
    "    \n",
    "\n",
    "    if RetProb:\n",
    "        return xFitSorted, yFitSorted/BaseAUC\n",
    "    else:\n",
    "        # Return a Polynomila Regression Function with Pre-trained coefficients and settings\n",
    "        return lambda x: RetFunc(x,                  # Input tensor (W),(B, W) or (B, C, W)\n",
    "                                 Order=PolyOrder,    # Polynomial order (integer)           \n",
    "                                 xMid=xAtMid,        # Boundary point separating left and right intervals \n",
    "                                 CoefLeft=CoefUp,    # Polynomial coefficients for left interval\n",
    "                                 CoefRight=CoefDn,   # Polynomial coefficients for Right interval  \n",
    "                                 xMin=xMinLeft,      # Minimum bound value for input x\n",
    "                                 xMax=xMaxRight,     # Maximum bound value for input x\n",
    "                                 MinProb=Epsilon,    # Minimum Clipping bound value for output probabilities\n",
    "                                 MaxProb=MaxY,       # Maximum Clipping bound value for output probabilities\n",
    "                                 Auc=BaseAUC)        # Normalization constant (Area Under Curve - PDF of Population)\n",
    "                                 #Print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039cb995",
   "metadata": {},
   "source": [
    "## For Evaluation / Debugging Purpose - DualPolyRegPDF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ad13357",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if DEBUG: \n",
    "    np.random.seed(0)\n",
    "    fig, bx = plt.subplots(1, 1, figsize=(9, 9));\n",
    "    data = np.random.normal(loc=0.5, scale=1.5, size=10000)\n",
    "    print(f'std: {np.std(data):.3f}')\n",
    "    data_tf = tf.constant(data, dtype=tf.float32)\n",
    "\n",
    "    cases = [   {\"UseKDE\": True,  \"RetProb\": True,  \"label\": \"Case 1: KDE + RetProb=True\"},\n",
    "                {\"UseKDE\": True,  \"RetProb\": False, \"label\": \"Case 2: KDE + RetProb=False\"},    \n",
    "                {\"UseKDE\": False, \"RetProb\": True,  \"label\": \"Case 3: HDE + RetProb=True\"},\n",
    "                {\"UseKDE\": False, \"RetProb\": False, \"label\": \"Case 4: HDE + RetProb=False\"},]\n",
    "\n",
    "    for case in cases:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(case[\"label\"])\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        result = DualPolyRegPDF(\n",
    "                                Superset=data_tf,\n",
    "                                Points=200,\n",
    "                                PolyOrder=5,\n",
    "                                TimesStd=5,\n",
    "                                UseKDE=case[\"UseKDE\"],\n",
    "                                RetProb=case[\"RetProb\"],\n",
    "                                Print=True\n",
    "                               )\n",
    "\n",
    "        if case[\"RetProb\"]:\n",
    "            # result is (x, y)\n",
    "            x_fit, y_fit = result\n",
    "        else:\n",
    "            # result is a callable function → compute probabilities\n",
    "            func = result\n",
    "            x_fit = np.linspace(np.min(data), np.max(data), 200).astype(np.float32)\n",
    "            yHat = func(tf.constant(x_fit, dtype=tf.float32))\n",
    "            y_fit =yHat.numpy()\n",
    "\n",
    "        auc = np.trapz(y_fit, x_fit)\n",
    "        print(\"AUC (np.trapz(y_fit, x_fit)):\", auc)\n",
    "\n",
    "        bx.plot(x_fit, y_fit, label=case[\"label\"])\n",
    "\n",
    "    bx.set_title(\"Comparison of CreateFunc4PDF Cases\")\n",
    "    bx.set_xlabel(\"x\")\n",
    "    bx.set_ylabel(\"PDF\")\n",
    "    bx.legend()\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b8e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
